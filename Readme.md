# Explainable hybrid framework for breast cancer histopathology diagnosis using wavelet decomposition and texture analysis

## Overview

This repository provides the implementation and experiment artifacts for a two-stage, explainable hybrid classification pipeline for histopathological image diagnosis evaluated on the BreakHis (breast) and LC25000 (lung/colon) datasets. The workflow consists of (1) handcrafted feature extraction using a two-level 2D discrete wavelet transform (DWT) followed by gray-level co-occurrence matrix (GLCM) texture descriptors computed across multiple distances and angles, and (2) classification using a one-vs-rest (OvR) ensemble stage whose class-probability outputs are appended to the handcrafted features to reinforce a final multiclass classifier. The repository includes the notebooks used to generate features, perform 5-fold evaluation, and export fold-wise reports and summary spreadsheets.

## Key Contributions

* A reproducible two-stage hybrid pipeline combining DWT sub-band decomposition with multi-distance/multi-angle GLCM texture features.
* OvR probability–extended feature reinforcement to improve separability in multiclass diagnosis.
* End-to-end 5-fold reporting with exportable fold-wise DOCX reports for both BreakHis and LC25000.

## Repository Contents

* `classification/`

  * `ovr-50-multiclass-onbreakhis.ipynb`: BreakHis 5-fold experiments (baseline OvR and probability-extended multiclass stage), including DOCX/XLSX export.
  * `ovr-reports-lc25000.ipynb`: LC25000 5-fold experiments (baseline OvR and probability-extended multiclass stage), including DOCX/XLSX export.
* `feature extraction/`

  * `breakhis-dwt-glcm-4-dist-4-angles.ipynb`: BreakHis DWT-GLCM feature extraction.
  * `lc25000-wt-glcm.ipynb`: LC25000 wavelet/GLCM feature extraction.
  * `aug_manifest_filled.csv`: BreakHis augmentation manifest (tracks operations and provenance).
  * `Folds.csv`: fold definitions.
  * *(Feature tables are not included due to GitHub file-size limits. They are generated locally by the feature-extraction notebooks.)*
* `results/`

  * `BreakHis/` and `LC25000/`: fold-wise DOCX reports generated by the notebooks (XLSX files, if present, may be manually compiled from the DOCX reports).

## System Requirements

The pipeline is CPU-compatible and can be executed on a standard workstation/laptop. In the reported experiments, the notebooks were executed on a Windows 11 (64-bit) machine with an Intel Core i9-14900HX CPU, 16 GB RAM, and a 1 TB NVMe SSD. GPU acceleration is not required.

## Software Requirements

* Python 3.10+ (tested with Python 3.13)
* Core libraries are listed in `requirements.txt` (includes: NumPy, Pandas, OpenCV, scikit-image, scikit-learn, PyWavelets, matplotlib/seaborn, python-docx, openpyxl, XGBoost, LightGBM, CatBoost, and utilities such as tqdm/joblib).

## Installation

1. Clone the repository and create a virtual environment.

2. Install dependencies:

```bash
python -m pip install --upgrade pip
pip install -r requirements.txt
```

**Encoding note (Windows):** ensure `requirements.txt` is saved as UTF-8. If it was created as UTF-16, convert it (PowerShell):

```powershell
Get-Content requirements.txt | Set-Content -Encoding utf8 requirements.txt
```

## Data Availability (PLOS ONE)

The datasets analyzed in this study are publicly available via Kaggle. The LC25000 lung and colon histopathological image dataset can be obtained from the Kaggle dataset page “Lung and Colon Cancer Histopathological Images” (andrewmvd). The BreakHis breast cancer histopathological image dataset can be obtained from the Kaggle dataset page “BreakHis” (ambarish).

This repository does not redistribute either dataset. For BreakHis, an augmented version was created as part of the experimental workflow; all augmentation operations are documented and traceable through the provided augmentation manifest (e.g., `feature extraction/aug_manifest_filled.csv`), enabling users to reproduce the augmented training data from the original BreakHis images.

## Code Availability (PLOS ONE)

All code required to reproduce the analyses and regenerate the reported outputs is provided in this repository, including feature extraction notebooks, classification/reporting notebooks, fold definitions, and the BreakHis augmentation manifest. The software environment can be recreated using the included `requirements.txt`.

> Replace this paragraph’s repository identifier with the public repository URL upon publication (e.g., GitHub/Zenodo).

## Datasets

### BreakHis Dataset

Source: Kaggle dataset “BreakHis” (ambarish).

Local layout (recommended):

* `data/BreakHis/BreaKHis_v1/` (dataset root)

BreakHis augmentation is applied to the training portion of the workflow; augmentation provenance is recorded in the provided manifest (`feature extraction/aug_manifest_filled.csv`).

### LC25000 Dataset

Source: Kaggle dataset “Lung and Colon Cancer Histopathological Images” (andrewmvd).

Local layout (recommended):

* `data/LC25000/lung_colon_image_set/` (dataset root)

No augmentation is required for LC25000 in this repository’s workflow.

## Reproducibility Summary

* **Inputs:** original datasets downloaded from Kaggle (BreakHis and LC25000). BreakHis augmentation steps are recorded in `feature extraction/aug_manifest_filled.csv`.
* **Feature extraction:** run the feature extraction notebooks to generate the wavelet/GLCM feature tables (feature files are not included in this repository due to size limits).
* **Evaluation:** run the classification notebooks to perform 5-fold evaluation.
* **Primary outputs:** fold-wise **DOCX** metric reports and exported **image** figures (e.g., mean±std confusion matrix visualizations) under `results/BreakHis/` and `results/LC25000/`.
* **Note on XLSX files:** XLSX summaries present in `results/` were compiled manually from the fold-wise DOCX reports and are not required to reproduce the core reported results.

## Quick Start

### 1) Place datasets locally

Create a local data directory (example):

* `data/BreakHis/` (downloaded from Kaggle)

  * `BreaKHis_v1/` (dataset root folder referenced by the notebooks)
* `data/LC25000/` (downloaded from Kaggle)

  * `lung_colon_image_set/` (dataset root folder referenced by the notebooks)

> If your extracted folders have different names, update the path variables in the notebooks as described under **Configuration Notes**.

### 2) Install dependencies

```bash
python -m pip install --upgrade pip
pip install -r requirements.txt
```

### 3) Run feature extraction

* **BreakHis**: open `feature extraction/breakhis-dwt-glcm-4-dist-4-angles.ipynb` and set:

  * `csv_path` to the local path of `aug_manifest_filled.csv`
  * `base_dir` to the local BreakHis base directory that contains the image files referenced in the manifest
  * (recommended) remove the `df[df["fold"] == 1]` filter if you want features for all images/folds

* **LC25000**: open `feature extraction/lc25000-wt-glcm.ipynb` and set:

  * `ROOT` to your local `lung_colon_image_set` directory
  * output filenames (recommended): `glcm_features_LC25000.csv` and/or `glcm_features_LC25000.xlsx`

### 4) Run classification and export reports

* **BreakHis**: open `classification/ovr-50-multiclass-onbreakhis.ipynb` and update the input file paths:

  * `../aug_manifest_filled.csv`
  * `../folds.csv` (ensure the filename matches your repo: `Folds.csv` vs `folds.csv`)
  * the generated BreakHis feature table CSV for your fold(s) (produced by the BreakHis feature-extraction notebook)

  Then run all cells. The notebook iterates over folds 1–5 and exports fold-wise DOCX reports.

* **LC25000**: open `classification/ovr-reports-lc25000.ipynb` and set:

  * `FILE_PATH` to the local feature table produced in step (3) (CSV/XLSX)

  Then run all cells. The notebook exports DOCX outputs for the selected fold(s).

## Workflow 1: Feature Extraction

### BreakHis Feature Extraction (DWT-GLCM)

Run `feature extraction/breakhis-dwt-glcm-4-dist-4-angles.ipynb` to extract handcrafted descriptors from histopathology images using:

* **Two-level 2D DWT** with **db1 (Haar)** wavelet, producing seven sub-bands
* **GLCM computation** per sub-band using distances **{1, 2, 3, 4}** and angles **{0°, 45°, 90°, 135°}**
* **Five Haralick features**: contrast, energy, homogeneity, entropy, and correlation

This yields a **455-dimensional** feature vector per image. The notebook can be configured to extract features for a specific fold (e.g., fold-1) or for all images depending on the applied filtering.

### LC25000 Feature Extraction (WT/DWT-GLCM)

Run `feature extraction/lc25000-wt-glcm.ipynb` to extract features using the same core configuration:

* **Two-level 2D DWT** with **db1 (Haar)** wavelet
* **GLCM distances {1, 2, 3, 4}** and angles **{0°, 45°, 90°, 135°}**
* **Five Haralick features**: contrast, energy, homogeneity, entropy, and correlation

The extracted feature table is saved as CSV/XLSX and is used as input to the LC25000 classification notebook.

## Workflow 2: Classification and Reporting

Both datasets follow the same three-stage evaluation logic:

1. **Baseline OvR:** Train and evaluate OvR ensembles (ET-OvR and RF-OvR) as baseline multiclass classifiers.
2. **ET-OvR probability extension:** Use ET-OvR to generate class-probability vectors, concatenate them to the handcrafted feature vector, then train/evaluate multiclass ML models on the reinforced feature space.
3. **RF-OvR probability extension:** Repeat the same reinforcement strategy using RF-OvR probabilities.

### BreakHis: Baseline OvR and OvR-Extended Classification

Run `classification/ovr-50-multiclass-onbreakhis.ipynb` to:

* iterate across folds (1–5)
* compute baseline OvR metrics (ET-OvR and RF-OvR)
* generate probability-extended features for the second-stage multiclass models
* export one DOCX report per method per fold under `results/BreakHis/`

### LC25000: Baseline OvR and OvR-Extended Classification

Run `classification/ovr-reports-lc25000.ipynb` to:

* generate stratified 5-fold splits
* compute baseline OvR metrics (ET-OvR and RF-OvR)
* generate probability-extended features for the second-stage multiclass models
* export one DOCX report per method per fold under `results/LC25000/`

## Outputs and File Formats

### Metrics Reports (DOCX)

For each dataset and each fold, the notebooks export **one DOCX report per method**, including the baseline OvR and the OvR-as-feature-extractor variants:

* `OvR results Multiclass fold-*.docx`
* `ET-OvR as feature extractor Multiclass results fold-*.docx`
* `RF-OvR as feature extractor Multiclass results fold-*.docx`

These reports contain the fold-wise evaluation metrics used in the study.

### Confusion Matrices and Plots

The repository may include exported summary figures (e.g., mean±std confusion-matrix visualization) under the corresponding `results/` subfolders when generated.

### Structured Diagnostic Reports (Supplementary)

Structured diagnostic reports (sample-level diagnostic summaries) were generated as supplementary material (including example figures used in the manuscript and a fixed number of samples per dataset). These supplementary artifacts are **not included in this repository**.

## Configuration Notes

### Paths and Directory Assumptions

These notebooks were authored with both Kaggle and local execution in mind. For local execution, you must update any hard-coded dataset paths:

* **BreakHis feature extraction** (`feature extraction/breakhis-dwt-glcm-4-dist-4-angles.ipynb`):

  * Update `csv_path` (augmentation manifest location) and `base_dir` (dataset root).
  * The notebook currently filters `fold == 1` when computing features. Remove or modify this filter if you want a complete feature table covering all images/folds.

* **LC25000 feature extraction** (`feature extraction/lc25000-wt-glcm.ipynb`):

  * Update `ROOT` from the Kaggle path to your local `lung_colon_image_set` directory.

* **BreakHis classification** (`classification/ovr-50-multiclass-onbreakhis.ipynb`):

  * Ensure the augmentation manifest (`aug_manifest_filled.csv`), fold file (`Folds.csv`/`folds.csv`), and feature table (`glcm_features_fold1.csv`) are reachable from the notebook’s working directory.
  * The notebook normalizes the feature-path column using the `BreaKHis_v1/` prefix; ensure your BreakHis dataset root folder matches this name or update the prefix accordingly.

* **LC25000 classification** (`classification/ovr-reports-lc25000.ipynb`):

  * Update `FILE_PATH` from the Kaggle path to your local feature table path.

### Label Mapping

To ensure consistent reporting across folds and across all exported confusion matrices and tables, class indices are mapped as follows.

**BreakHis (8 classes):**

* 0 → adenosis
* 1 → ductal carcinoma
* 2 → fibroadenoma
* 3 → lobular carcinoma
* 4 → mucinous carcinoma
* 5 → papillary carcinoma
* 6 → phyllodes tumor
* 7 → tubular adenoma

**LC25000 (5 classes):**

* 0 → colon_aca
* 1 → colon_n
* 2 → lung_aca
* 3 → lung_n
* 4 → lung_scc

### Fold Strategy and Splits

**BreakHis:** Fold assignment follows the original fold specification distributed with the BreakHis dataset. The fold file is used to define non-overlapping splits, and augmentation is applied after the split as part of the training-data preparation workflow (augmentation provenance is tracked in the manifest).

**LC25000:** As no official fold specification is provided, folds are generated using a standard 5-fold stratified split (StratifiedKFold) over the full dataset to preserve class proportions in each fold.

## How to Cite

If you use this repository, please cite:

Mustafa Adil Hussain, Aqilah Baseri Huddin, Fazida Hanim Hashim, and Ahmed Sameer Alani. *Explainable hybrid framework for breast cancer histopathology diagnosis using wavelet decomposition and texture analysis*. Under review, 2025.

### BibTeX

```bibtex
@unpublished{hussain2025explainable,
  title        = {Explainable hybrid framework for breast cancer histopathology diagnosis using wavelet decomposition and texture analysis},
  author       = {Hussain, Mustafa Adil and Huddin, Aqilah Baseri and Hashim, Fazida Hanim and Alani, Ahmed Sameer},
  year         = {2025},
  note         = {Under review}
}
```

## Acknowledgments
The authors would like to thank the Ministry of Higher Education and Universiti Kebangsaan Malaysia (UKM) for the Fundamental Research Grant Scheme (Grant no FRGS/1/2023/TK07/UKM/02/6) for their support in conducting this research.

## Contact

For questions, bug reports, or reproduction issues, please open an issue in the repository.
